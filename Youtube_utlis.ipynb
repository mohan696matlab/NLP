{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5f59df2b4a4fd8bd702e90669cc5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = 128001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def llm_generate(messages, max_tokens=256,do_sample=False):\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    # print(prompt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=do_sample,\n",
    "            max_new_tokens=max_tokens,\n",
    "        )\n",
    "\n",
    "    processed_text = tokenizer.decode(output[0][len(inputs.input_ids[0])+3:], skip_special_tokens=True)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the RAW Transcription "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/transcription.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript_txt = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the title for the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Here are some possible video title options based on the provided transcript:\n",
      "\n",
      "1. \"How to Train a Small Language Model using PyTorch\"\n",
      "2. \"Building a Simple Language Model from Scratch with PyTorch\"\n",
      "3. \"Understanding Language Models: A Simplified Explanation\"\n",
      "4. \"Small Language Model Tutorial: From Basics to Implementation\"\n",
      "5. \"PyTorch Language Model Tutorial: Training a Small Language Model\"\n",
      "6. \"Language Model 101: How to Create a Small Language Model with PyTorch\"\n",
      "7. \"Simplifying Language Models: A Step-by-Step Guide with PyTorch\"\n",
      "8. \"From Text to Tokens: Training a Small Language Model with PyTorch\"\n",
      "9. \"The Basics of Language Models: A Simplified Explanation with PyTorch\"\n",
      "10. \"Building a Small Language Model: A PyTorch Tutorial for Beginners\"\n",
      "\n",
      "Each title is concise, starts with the most impactful keyword, and is optimized for high click-through rates. They also provide a clear idea of what the video will cover, making it appealing to potential viewers.\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = ''' \n",
    "Generate a list of possible video titles based on the provided video topic. Each title should be concise (maximum 60 characters) and start with the most impactful keyword. The titles should be engaging, culturally relevant, and optimized for high click-through rates.\n",
    "'''\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": f'''TRANSCRIPT TEXT: {transcript_txt}'''},\n",
    "]\n",
    "\n",
    "video_title_ideas = llm_generate(messages,max_tokens=256)\n",
    "print(video_title_ideas)\n",
    "\n",
    "with open('results/video_title_ideas.txt', \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(video_title_ideas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the Description for the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In this video, we're exploring LangChain Agents and delving into what they're all about, how they work, and the benefits they bring to businesses. An agent is essentially a combination of a language model and one or more tools, allowing it to solve specific problems in a way that's similar to how a person would use tools like Excel or data tables. By combining a language model with tools, we empower it to tackle complex tasks, and LangChain is the framework that makes this possible.\n",
      "\n",
      "We're starting with an example of building a chatbot for an e-commerce business, where the language model needs to access customer data, such as browsing history and purchase records, to provide a personalized experience. However, current language models lack this information, so we need to get them access to customer data through microservices and APIs. LangChain's connectors to APIs and computational resources are called tools, and when combined with a language model, we get an agent.\n",
      "\n",
      "We're taking a Python function that extracts data from the Shopify API and turning it into a tool using LangChain's structured tool. This tool can then be used to create an agent that interacts with the Shopify API, allowing the language model to access and process customer data. The React framework powers the agent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SYSTEM_PROMPT = ''' \n",
    "Generate a compelling summary for the given video, incorporating all key topics and important keywords naturally. The summary should be engaging, concise, and clearly convey the video's main takeaways while maintaining a natural flow.\n",
    "Do not include any additional text or numbering. DO NOT USE MARKDOWN.\n",
    "'''\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": f'''TRANSCRIPT TEXT: {transcript_txt}'''},\n",
    "]\n",
    "\n",
    "video_description = llm_generate(messages,max_tokens=256,do_sample=True)\n",
    "\n",
    "print(video_description)\n",
    "\n",
    "with open('results/video_description.txt', \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(video_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the key topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "In this video, we're going to have a closer look at LangChain Agents and understand what  Agents are all about.  First we're going to dive into what an agent is and understand how agents work under the  hood of LangChain.  Then we're going to have a look at what we can do with agents that we couldn't do before  and some of the future implications for businesses that are already investing in technology,  data and analytics.  And finally, I'm going to show you how to get started building your own\n",
      "----------------------------------------\n",
      "Topic 2:\n",
      "knows about your products, which is better than before, but it's still not good enough. Because what does a chatbot really need to know in order to give the customers a good  customer experience? The chatbot needs to know stuff about the customer. If this chatbot is on  a webpage, it needs to know the context of the visit. And this could be information like,  is this a new potential customer or an existing customer? Or what is the browsing history of this visitor?  What products do we recommend\n",
      "----------------------------------------\n",
      "Topic 3:\n",
      "information through APIs. In LangChain, connectors to APIs and computational resources are called  tools and agents are what we get when we combine a language model with one or more tools.  By combining a language model with a set of tools, we are empowering the language model to solve specific problems,  much in the same way that a regular person would use tools like Python Excel or data tables with information to solve a specific task. In the last video we saw an example of a Langtrain agent\n",
      "----------------------------------------\n",
      "Topic 4:\n",
      "different channels a business uses  to communicate with their customers  or potential customers.  And we have five main channels.  So the five main ways businesses communicate online  with their customers are through paid and social media,  their web page,  chats, email and SMS.  The online customer experience is primarily created in those channels and is controlled  by text, images and video.  The text part can be generated by language models and businesses are already working  on using chat\n",
      "----------------------------------------\n",
      "Topic 5:\n",
      "on using chat GBT for this.  The images in the video will also be created by AI and companies are now working on using chat GBT for this. The images in the video will also be created by AI,  and companies are now working on using mid-journey, stable  diffusion, and control net for this.  Let's forget about the images and video part for now.  We'll get back to that in later videos  and just focus on the language modeling.  We talked about before that the language models don't know  enough about\n",
      "----------------------------------------\n",
      "Topic 6:\n",
      "this video. The first thing we're gonna do we're going to load the needed  libraries, I'm going to load the environment variables and here we have  the Python function that will extract the data from the Shopify API. It takes an  object name as input that could be customers, orders, or products and it extracts 250 items.  I've already covered how you get the access token to extract the data from Shopify in an earlier video,  I'll put a link to that video below this one.  Let me just show you\n",
      "----------------------------------------\n",
      "Topic 7:\n",
      "and it will return the number of items as a string.  And now we have everything we need to define the agent.  The language model, in this case, GBT4,  will seek to infer what it needs to do with the tool  from the signature of the function.  So we're going to define an agent chain  by initializing the agent with the tools, in this case,  just one tool, the chat model, and the agent type.  And now we can ask GBT4 to count the number of orders, customers,  or products, or whatever in the Shopify\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "def find_new_topics_from_transcript(transcript, chunk_size=500, chunk_overlap=20, similarity_threshold=-5):\n",
    "    \"\"\"\n",
    "    Finds new topics in a podcast transcript using chunking and cross-encoder similarity.\n",
    "\n",
    "    Args:\n",
    "        transcript (str): The podcast transcript.\n",
    "        chunk_size (int): The size of each text chunk.\n",
    "        chunk_overlap (int): The overlap between text chunks.\n",
    "        similarity_threshold (float): The threshold for similarity between chunks.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of new topic chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_text(transcript)\n",
    "\n",
    "    model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "    new_topics = [chunks[0]]  # Initialize with the first chunk\n",
    "    reference_chunk = chunks[0]\n",
    "\n",
    "    for chunk in chunks[1:]:\n",
    "        pairs = [[reference_chunk, chunk]]\n",
    "        scores = model.predict(pairs)\n",
    "        similarity_score = scores[0]\n",
    "\n",
    "        if similarity_score < similarity_threshold:\n",
    "            new_topics.append(chunk)\n",
    "            reference_chunk = chunk  # Update the reference chunk\n",
    "        #else:\n",
    "        #   print(f\"Similarity {similarity_score:.4f} found between: \\n{reference_chunk[:100]}...\\nand \\n{chunk[:100]}...\")\n",
    "\n",
    "    return new_topics\n",
    "\n",
    "\n",
    "new_topics = find_new_topics_from_transcript(transcript_txt)\n",
    "\n",
    "for i, topic in enumerate(new_topics):\n",
    "    print(f\"Topic {i+1}:\\n{topic}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look through the transcript for time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00:00': \"In this video, we're going to have a closer look at LangChain Agents and understand what  Agents are all about.  First we're going to dive into what an agent is and understand how agents work under the  hood of LangChain.  Then we're going to have a look at what we can do with agents that we couldn't do before  and some of the future implications for businesses that are already investing in technology,  data and analytics.  And finally, I'm going to show you how to get started building your own\", '01:18': \"knows about your products, which is better than before, but it's still not good enough. Because what does a chatbot really need to know in order to give the customers a good  customer experience? The chatbot needs to know stuff about the customer. If this chatbot is on  a webpage, it needs to know the context of the visit. And this could be information like,  is this a new potential customer or an existing customer? Or what is the browsing history of this visitor?  What products do we recommend\", '02:14': 'information through APIs. In LangChain, connectors to APIs and computational resources are called  tools and agents are what we get when we combine a language model with one or more tools.  By combining a language model with a set of tools, we are empowering the language model to solve specific problems,  much in the same way that a regular person would use tools like Python Excel or data tables with information to solve a specific task. In the last video we saw an example of a Langtrain agent', '04:18': 'different channels a business uses  to communicate with their customers  or potential customers.  And we have five main channels.  So the five main ways businesses communicate online  with their customers are through paid and social media,  their web page,  chats, email and SMS.  The online customer experience is primarily created in those channels and is controlled  by text, images and video.  The text part can be generated by language models and businesses are already working  on using chat', '04:43': \"on using chat GBT for this.  The images in the video will also be created by AI and companies are now working on using chat GBT for this. The images in the video will also be created by AI,  and companies are now working on using mid-journey, stable  diffusion, and control net for this.  Let's forget about the images and video part for now.  We'll get back to that in later videos  and just focus on the language modeling.  We talked about before that the language models don't know  enough about\", '06:21': \"this video. The first thing we're gonna do we're going to load the needed  libraries, I'm going to load the environment variables and here we have  the Python function that will extract the data from the Shopify API. It takes an  object name as input that could be customers, orders, or products and it extracts 250 items.  I've already covered how you get the access token to extract the data from Shopify in an earlier video,  I'll put a link to that video below this one.  Let me just show you\", '07:59': \"and it will return the number of items as a string.  And now we have everything we need to define the agent.  The language model, in this case, GBT4,  will seek to infer what it needs to do with the tool  from the signature of the function.  So we're going to define an agent chain  by initializing the agent with the tools, in this case,  just one tool, the chat model, and the agent type.  And now we can ask GBT4 to count the number of orders, customers,  or products, or whatever in the Shopify\"}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_srt(subtitle_file):\n",
    "    \"\"\"Parses the subtitle file and returns a list of (start_time, text) tuples.\"\"\"\n",
    "    subtitles = []\n",
    "    pattern = re.compile(r\"(\\d+)\\n(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n(.+?)(?=\\n\\d+\\n|\\Z)\", re.DOTALL)\n",
    "    \n",
    "    with open(subtitle_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    matches = pattern.findall(content)\n",
    "    for _, start_time, text in matches:\n",
    "        cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "        # Convert HH:MM:SS,mmm to MM:SS\n",
    "        hours, minutes, seconds_ms = start_time.split(\":\")\n",
    "        seconds, milliseconds = seconds_ms.split(\",\")\n",
    "        start_time_MMSS = f\"{minutes}:{seconds}\"\n",
    "        subtitles.append((start_time_MMSS, cleaned_text))\n",
    "    \n",
    "    return subtitles\n",
    "\n",
    "def find_best_timestamps(subtitle_file, queries):\n",
    "    \"\"\"Finds the best subtitle match for each query and returns the start timestamps.\"\"\"\n",
    "    subtitles = parse_srt(subtitle_file)\n",
    "    texts = [text for _, text in subtitles]\n",
    "    start_times = [start for start, _ in subtitles]\n",
    "\n",
    "    model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    \n",
    "    query_timestamps = {}\n",
    "    for query in queries:\n",
    "        scores = model.predict([[query, text] for text in texts])\n",
    "        best_idx = scores.argmax()\n",
    "        query_timestamps[start_times[best_idx]] = query\n",
    "    \n",
    "    return query_timestamps\n",
    "\n",
    "# Example usage:\n",
    "queries =  new_topics\n",
    "\n",
    "subtitle_file = \"results/subtitles.srt\"  # Replace with your actual subtitle file path\n",
    "\n",
    "timestamps = find_best_timestamps(subtitle_file, queries)\n",
    "# Function to convert timestamp to minutes and seconds for sorting\n",
    "def time_to_seconds(time_str):\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "# Sort dictionary by timestamp\n",
    "timestamps = dict(sorted(timestamps.items(), key=lambda x: time_to_seconds(x[0])))\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rephrase the chapter names using llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase_chapter(chapter_text):\n",
    "    SYSTEM_PROMPT = '''rephrase this chapter name to make it look like a standalone video title (not too flashy keep it simple, do not use bloat words like mastering, unlocking, embarking etc).\n",
    "    The sentence should be easily understandable and concise. \n",
    "    however the title should not be more than 60 characters\n",
    "    Do not include any additional text or numbering.'''\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f'''CHAPTER TEXT: {chapter_text}'''}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    # print(prompt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            max_new_tokens=50,\n",
    "        )\n",
    "\n",
    "    processed_text = tokenizer.decode(output[0][len(inputs.input_ids[0])+3:], skip_special_tokens=True)\n",
    "    return processed_text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\envs\\torch_env\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\miniconda3\\envs\\torch_env\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00 - Understanding LangChain Agents\n",
      "01:18 - Unlocking Customer Insights for Better Chatbot Experience\n",
      "02:14 - Building Tools for Language Models\n",
      "04:18 - 5 Key Channels for Business Communication\n",
      "04:43 - ChatGPT: The Future of Language Understanding\n",
      "06:21 - Shopify API Data Extraction with Python\n",
      "07:59 - Defining a Shopify Agent with GBT4\n"
     ]
    }
   ],
   "source": [
    "chapter_timestamps=[]\n",
    "\n",
    "for ts in timestamps:\n",
    "    chapter_name = rephrase_chapter(timestamps[ts])\n",
    "    chapter_timestamps.append(f'''{ts} - {chapter_name.strip('\"').strip(\"'\")}''')\n",
    "\n",
    "print('\\n'.join(chapter_timestamps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube video downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Xi9Ui-9qcPw&t=170s\n",
      "[youtube] Xi9Ui-9qcPw: Downloading webpage\n",
      "[youtube] Xi9Ui-9qcPw: Downloading tv client config\n",
      "[youtube] Xi9Ui-9qcPw: Downloading player 4fcd6e4a\n",
      "[youtube] Xi9Ui-9qcPw: Downloading tv player API JSON\n",
      "[youtube] Xi9Ui-9qcPw: Downloading ios player API JSON\n",
      "[youtube] Xi9Ui-9qcPw: Downloading m3u8 information\n",
      "[info] Xi9Ui-9qcPw: Downloading 1 format(s): 248+251\n",
      "[download] Destination: LangChain Agents： Simply Explained!.f248.webm\n",
      "[download] 100% of   12.45MiB in 00:00:00 at 43.77MiB/s    \n",
      "[download] Destination: LangChain Agents： Simply Explained!.f251.webm\n",
      "[download] 100% of    8.59MiB in 00:00:00 at 43.95MiB/s  \n",
      "[Merger] Merging formats into \"LangChain Agents： Simply Explained!.mp4\"\n",
      "Deleting original file LangChain Agents： Simply Explained!.f248.webm (pass -k to keep)\n",
      "Deleting original file LangChain Agents： Simply Explained!.f251.webm (pass -k to keep)\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def download_youtube_video(url, output_path=\".\"):\n",
    "    \"\"\"\n",
    "    Downloads a YouTube video using yt-dlp.\n",
    "\n",
    "    Args:\n",
    "        url (str): The YouTube video URL.\n",
    "        output_path (str): The directory where the video will be saved.\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        'outtmpl': f'{output_path}/%(title)s.%(ext)s', # output template\n",
    "        'format': 'bestvideo[height<=?1080]+bestaudio/best', # best video and audio, max 1080p\n",
    "        'merge_output_format': 'mp4', # merge to mp4\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(\"Download complete.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "video_url = \"https://www.youtube.com/watch?v=Xi9Ui-9qcPw&t=170s\" # Replace with your YouTube URL.\n",
    "download_youtube_video(video_url) # Downloads to the current directory\n",
    "\n",
    "# Example with a specific output path:\n",
    "# download_youtube_video(video_url, output_path=\"/path/to/your/videos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
