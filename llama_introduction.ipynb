{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    # {\"role\": \"system\", \"content\": '''respind to the user as if you are stewie from family guy'''},\n",
    "    {\"role\": \"user\", \"content\": '''who is mohan dash ?'''},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 17 Feb 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "who is mohan dash?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Mohan Dash is a popular Indian actor who has appeared in numerous films and television shows in the Malayalam language. He is known for his versatility and range in playing different roles.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(conversation, tokenize=False)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "# print(prompt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "\n",
    "processed_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 17 Feb 2025\n",
      "\n",
      "user\n",
      "\n",
      "who is mohan dash?assistant\n",
      "\n",
      "Mohan Dash is an Indian television actor, model, and comedian. He is best known for his work in the Indian television industry, particularly in the popular show \"Bhabhimaan\" and \"Bhabhimaan 2\".assistant\n",
      "\n",
      "Mohan Dash is a popular Indian television actor, model, and comedian. He is known for his energetic and charismatic performances in various TV shows, including \"Bhabhimaan\" and \"Bhabh\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt , return_tensors=\"pt\").input_ids\n",
    "model.eval()\n",
    "\n",
    "max_tokens=100\n",
    "for _ in range(max_tokens):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.to('cuda'))\n",
    "        logits = outputs.logits[:, -1, :].cpu()  # Get logits of the last token\n",
    "        next_token_id = torch.argmax(logits, dim=-1).unsqueeze(0)  # Greedy decoding\n",
    "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    time.sleep(0.1)  # Add a delay for a smoother experience\n",
    "    print(tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "\n",
    "# print(tokenizer.decode(input_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the LLAMA model on a sigle text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 17 Feb 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "who is mohan dash ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Mohan Dash is a reserach engineer with a PhD in AI.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": '''who is mohan dash ?'''},\n",
    "    {\"role\": \"assistant\", \"content\": '''Mohan Dash is a reserach engineer with a PhD in AI.'''},\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(conversation, tokenize=False)\n",
    "print(prompt)\n",
    "\n",
    "inputs = tokenizer(prompt , return_tensors=\"pt\")\n",
    "\n",
    "input_ids = inputs.input_ids[:,:-1].to('cuda')\n",
    "labels = inputs.input_ids[:,1:].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.3745\n",
      "Epoch 2/30, Loss: 0.3670\n",
      "Epoch 3/30, Loss: 0.3596\n",
      "Epoch 4/30, Loss: 0.3544\n",
      "Epoch 5/30, Loss: 0.3509\n",
      "Epoch 6/30, Loss: 0.3470\n",
      "Epoch 7/30, Loss: 0.3434\n",
      "Epoch 8/30, Loss: 0.3396\n",
      "Epoch 9/30, Loss: 0.3347\n",
      "Epoch 10/30, Loss: 0.3321\n",
      "Epoch 11/30, Loss: 0.3269\n",
      "Epoch 12/30, Loss: 0.3245\n",
      "Epoch 13/30, Loss: 0.3180\n",
      "Epoch 14/30, Loss: 0.3142\n",
      "Epoch 15/30, Loss: 0.3100\n",
      "Epoch 16/30, Loss: 0.3064\n",
      "Epoch 17/30, Loss: 0.2975\n",
      "Epoch 18/30, Loss: 0.2939\n",
      "Epoch 19/30, Loss: 0.2889\n",
      "Epoch 20/30, Loss: 0.2839\n",
      "Epoch 21/30, Loss: 0.2804\n",
      "Epoch 22/30, Loss: 0.2745\n",
      "Epoch 23/30, Loss: 0.2713\n",
      "Epoch 24/30, Loss: 0.2674\n",
      "Epoch 25/30, Loss: 0.2593\n",
      "Epoch 26/30, Loss: 0.2547\n",
      "Epoch 27/30, Loss: 0.2524\n",
      "Epoch 28/30, Loss: 0.2502\n",
      "Epoch 29/30, Loss: 0.2483\n",
      "Epoch 30/30, Loss: 0.2480\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "# Training loop\n",
    "model.train()\n",
    "num_epochs = 30  # You can increase if needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(input_ids, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 17 Feb 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is cricket?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ohan is resach with in. in. a in. a. in. a. a. in. a. in. a. in. a. in. a. in. a. in. a. in. a. a. in. a. in. a. a. a. a. a. in. a. in. a. a. a. a. a. a. a. a. a. a. a. a. a. a.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": '''what is cricket?'''},\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt , return_tensors=\"pt\").to(device)\n",
    "# print(prompt)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "\n",
    "processed_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "print(processed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
