{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf50a1428bf4ad7bf9ef2dedd43fc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095.841064453125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"OdiaGenAI/hardcode_odia_qa_105\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '',\n",
       " 'english_input': '',\n",
       " 'english_instruction': 'Who are you?',\n",
       " 'instruction': 'ଆପଣ କିଏ?',\n",
       " 'output': 'ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଯାହାକି ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ଏକ ଭାଷା ମଡେଲ।',\n",
       " 'english_output': 'I am Olive a chatbot assistant, a language model trained by researchers from OdiaGenAI.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset\n",
    "class LlamaDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        question=sample['instruction']\n",
    "        answer = sample['output']\n",
    "        prompt = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "        full_text = prompt+f'''{answer}।<|eot_id|>'''\n",
    "\n",
    "        tokenized = tokenizer(full_text, truncation=True, add_special_tokens=False, padding=\"max_length\", max_length=380)\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "        # Tokenize just the prompt to get the split point\n",
    "        prompt_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "        answer_start = len(prompt_ids)\n",
    "\n",
    "        # Mask everything before answer_start\n",
    "        labels = [-100] * answer_start + input_ids[answer_start:]\n",
    "        # Mask out padding as well\n",
    "        labels = [\n",
    "            label if token != tokenizer.pad_token_id else -100\n",
    "            for label, token in zip(labels, input_ids)\n",
    "        ]\n",
    "    \n",
    "        return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"attention_mask\": torch.tensor(attention_mask),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LlamaDataset(dataset['train'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.float16\n",
      "model.layers.0.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.0.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.0.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.0.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.0.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.0.mlp.up_proj.weight torch.uint8\n",
      "model.layers.0.mlp.down_proj.weight torch.uint8\n",
      "model.layers.0.input_layernorm.weight torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight torch.float16\n",
      "model.layers.1.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.1.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.1.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.1.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.1.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.1.mlp.up_proj.weight torch.uint8\n",
      "model.layers.1.mlp.down_proj.weight torch.uint8\n",
      "model.layers.1.input_layernorm.weight torch.float16\n",
      "model.layers.1.post_attention_layernorm.weight torch.float16\n",
      "model.layers.2.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.2.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.2.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.2.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.2.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.2.mlp.up_proj.weight torch.uint8\n",
      "model.layers.2.mlp.down_proj.weight torch.uint8\n",
      "model.layers.2.input_layernorm.weight torch.float16\n",
      "model.layers.2.post_attention_layernorm.weight torch.float16\n",
      "model.layers.3.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.3.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.3.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.3.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.3.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.3.mlp.up_proj.weight torch.uint8\n",
      "model.layers.3.mlp.down_proj.weight torch.uint8\n",
      "model.layers.3.input_layernorm.weight torch.float16\n",
      "model.layers.3.post_attention_layernorm.weight torch.float16\n",
      "model.layers.4.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.4.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.4.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.4.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.4.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.4.mlp.up_proj.weight torch.uint8\n",
      "model.layers.4.mlp.down_proj.weight torch.uint8\n",
      "model.layers.4.input_layernorm.weight torch.float16\n",
      "model.layers.4.post_attention_layernorm.weight torch.float16\n",
      "model.layers.5.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.5.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.5.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.5.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.5.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.5.mlp.up_proj.weight torch.uint8\n",
      "model.layers.5.mlp.down_proj.weight torch.uint8\n",
      "model.layers.5.input_layernorm.weight torch.float16\n",
      "model.layers.5.post_attention_layernorm.weight torch.float16\n",
      "model.layers.6.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.6.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.6.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.6.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.6.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.6.mlp.up_proj.weight torch.uint8\n",
      "model.layers.6.mlp.down_proj.weight torch.uint8\n",
      "model.layers.6.input_layernorm.weight torch.float16\n",
      "model.layers.6.post_attention_layernorm.weight torch.float16\n",
      "model.layers.7.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.7.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.7.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.7.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.7.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.7.mlp.up_proj.weight torch.uint8\n",
      "model.layers.7.mlp.down_proj.weight torch.uint8\n",
      "model.layers.7.input_layernorm.weight torch.float16\n",
      "model.layers.7.post_attention_layernorm.weight torch.float16\n",
      "model.layers.8.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.8.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.8.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.8.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.8.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.8.mlp.up_proj.weight torch.uint8\n",
      "model.layers.8.mlp.down_proj.weight torch.uint8\n",
      "model.layers.8.input_layernorm.weight torch.float16\n",
      "model.layers.8.post_attention_layernorm.weight torch.float16\n",
      "model.layers.9.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.9.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.9.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.9.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.9.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.9.mlp.up_proj.weight torch.uint8\n",
      "model.layers.9.mlp.down_proj.weight torch.uint8\n",
      "model.layers.9.input_layernorm.weight torch.float16\n",
      "model.layers.9.post_attention_layernorm.weight torch.float16\n",
      "model.layers.10.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.10.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.10.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.10.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.10.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.10.mlp.up_proj.weight torch.uint8\n",
      "model.layers.10.mlp.down_proj.weight torch.uint8\n",
      "model.layers.10.input_layernorm.weight torch.float16\n",
      "model.layers.10.post_attention_layernorm.weight torch.float16\n",
      "model.layers.11.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.11.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.11.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.11.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.11.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.11.mlp.up_proj.weight torch.uint8\n",
      "model.layers.11.mlp.down_proj.weight torch.uint8\n",
      "model.layers.11.input_layernorm.weight torch.float16\n",
      "model.layers.11.post_attention_layernorm.weight torch.float16\n",
      "model.layers.12.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.12.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.12.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.12.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.12.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.12.mlp.up_proj.weight torch.uint8\n",
      "model.layers.12.mlp.down_proj.weight torch.uint8\n",
      "model.layers.12.input_layernorm.weight torch.float16\n",
      "model.layers.12.post_attention_layernorm.weight torch.float16\n",
      "model.layers.13.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.13.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.13.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.13.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.13.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.13.mlp.up_proj.weight torch.uint8\n",
      "model.layers.13.mlp.down_proj.weight torch.uint8\n",
      "model.layers.13.input_layernorm.weight torch.float16\n",
      "model.layers.13.post_attention_layernorm.weight torch.float16\n",
      "model.layers.14.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.14.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.14.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.14.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.14.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.14.mlp.up_proj.weight torch.uint8\n",
      "model.layers.14.mlp.down_proj.weight torch.uint8\n",
      "model.layers.14.input_layernorm.weight torch.float16\n",
      "model.layers.14.post_attention_layernorm.weight torch.float16\n",
      "model.layers.15.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.15.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.15.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.15.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.15.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.15.mlp.up_proj.weight torch.uint8\n",
      "model.layers.15.mlp.down_proj.weight torch.uint8\n",
      "model.layers.15.input_layernorm.weight torch.float16\n",
      "model.layers.15.post_attention_layernorm.weight torch.float16\n",
      "model.layers.16.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.16.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.16.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.16.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.16.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.16.mlp.up_proj.weight torch.uint8\n",
      "model.layers.16.mlp.down_proj.weight torch.uint8\n",
      "model.layers.16.input_layernorm.weight torch.float16\n",
      "model.layers.16.post_attention_layernorm.weight torch.float16\n",
      "model.layers.17.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.17.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.17.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.17.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.17.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.17.mlp.up_proj.weight torch.uint8\n",
      "model.layers.17.mlp.down_proj.weight torch.uint8\n",
      "model.layers.17.input_layernorm.weight torch.float16\n",
      "model.layers.17.post_attention_layernorm.weight torch.float16\n",
      "model.layers.18.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.18.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.18.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.18.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.18.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.18.mlp.up_proj.weight torch.uint8\n",
      "model.layers.18.mlp.down_proj.weight torch.uint8\n",
      "model.layers.18.input_layernorm.weight torch.float16\n",
      "model.layers.18.post_attention_layernorm.weight torch.float16\n",
      "model.layers.19.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.19.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.19.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.19.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.19.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.19.mlp.up_proj.weight torch.uint8\n",
      "model.layers.19.mlp.down_proj.weight torch.uint8\n",
      "model.layers.19.input_layernorm.weight torch.float16\n",
      "model.layers.19.post_attention_layernorm.weight torch.float16\n",
      "model.layers.20.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.20.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.20.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.20.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.20.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.20.mlp.up_proj.weight torch.uint8\n",
      "model.layers.20.mlp.down_proj.weight torch.uint8\n",
      "model.layers.20.input_layernorm.weight torch.float16\n",
      "model.layers.20.post_attention_layernorm.weight torch.float16\n",
      "model.layers.21.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.21.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.21.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.21.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.21.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.21.mlp.up_proj.weight torch.uint8\n",
      "model.layers.21.mlp.down_proj.weight torch.uint8\n",
      "model.layers.21.input_layernorm.weight torch.float16\n",
      "model.layers.21.post_attention_layernorm.weight torch.float16\n",
      "model.layers.22.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.22.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.22.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.22.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.22.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.22.mlp.up_proj.weight torch.uint8\n",
      "model.layers.22.mlp.down_proj.weight torch.uint8\n",
      "model.layers.22.input_layernorm.weight torch.float16\n",
      "model.layers.22.post_attention_layernorm.weight torch.float16\n",
      "model.layers.23.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.23.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.23.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.23.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.23.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.23.mlp.up_proj.weight torch.uint8\n",
      "model.layers.23.mlp.down_proj.weight torch.uint8\n",
      "model.layers.23.input_layernorm.weight torch.float16\n",
      "model.layers.23.post_attention_layernorm.weight torch.float16\n",
      "model.layers.24.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.24.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.24.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.24.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.24.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.24.mlp.up_proj.weight torch.uint8\n",
      "model.layers.24.mlp.down_proj.weight torch.uint8\n",
      "model.layers.24.input_layernorm.weight torch.float16\n",
      "model.layers.24.post_attention_layernorm.weight torch.float16\n",
      "model.layers.25.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.25.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.25.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.25.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.25.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.25.mlp.up_proj.weight torch.uint8\n",
      "model.layers.25.mlp.down_proj.weight torch.uint8\n",
      "model.layers.25.input_layernorm.weight torch.float16\n",
      "model.layers.25.post_attention_layernorm.weight torch.float16\n",
      "model.layers.26.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.26.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.26.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.26.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.26.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.26.mlp.up_proj.weight torch.uint8\n",
      "model.layers.26.mlp.down_proj.weight torch.uint8\n",
      "model.layers.26.input_layernorm.weight torch.float16\n",
      "model.layers.26.post_attention_layernorm.weight torch.float16\n",
      "model.layers.27.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.27.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.27.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.27.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.27.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.27.mlp.up_proj.weight torch.uint8\n",
      "model.layers.27.mlp.down_proj.weight torch.uint8\n",
      "model.layers.27.input_layernorm.weight torch.float16\n",
      "model.layers.27.post_attention_layernorm.weight torch.float16\n",
      "model.norm.weight torch.float16\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],param[1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.float32\n",
      "model.layers.0.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.0.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.0.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.0.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.0.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.0.mlp.up_proj.weight torch.uint8\n",
      "model.layers.0.mlp.down_proj.weight torch.uint8\n",
      "model.layers.0.input_layernorm.weight torch.float32\n",
      "model.layers.0.post_attention_layernorm.weight torch.float32\n",
      "model.layers.1.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.1.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.1.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.1.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.1.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.1.mlp.up_proj.weight torch.uint8\n",
      "model.layers.1.mlp.down_proj.weight torch.uint8\n",
      "model.layers.1.input_layernorm.weight torch.float32\n",
      "model.layers.1.post_attention_layernorm.weight torch.float32\n",
      "model.layers.2.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.2.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.2.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.2.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.2.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.2.mlp.up_proj.weight torch.uint8\n",
      "model.layers.2.mlp.down_proj.weight torch.uint8\n",
      "model.layers.2.input_layernorm.weight torch.float32\n",
      "model.layers.2.post_attention_layernorm.weight torch.float32\n",
      "model.layers.3.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.3.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.3.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.3.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.3.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.3.mlp.up_proj.weight torch.uint8\n",
      "model.layers.3.mlp.down_proj.weight torch.uint8\n",
      "model.layers.3.input_layernorm.weight torch.float32\n",
      "model.layers.3.post_attention_layernorm.weight torch.float32\n",
      "model.layers.4.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.4.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.4.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.4.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.4.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.4.mlp.up_proj.weight torch.uint8\n",
      "model.layers.4.mlp.down_proj.weight torch.uint8\n",
      "model.layers.4.input_layernorm.weight torch.float32\n",
      "model.layers.4.post_attention_layernorm.weight torch.float32\n",
      "model.layers.5.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.5.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.5.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.5.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.5.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.5.mlp.up_proj.weight torch.uint8\n",
      "model.layers.5.mlp.down_proj.weight torch.uint8\n",
      "model.layers.5.input_layernorm.weight torch.float32\n",
      "model.layers.5.post_attention_layernorm.weight torch.float32\n",
      "model.layers.6.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.6.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.6.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.6.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.6.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.6.mlp.up_proj.weight torch.uint8\n",
      "model.layers.6.mlp.down_proj.weight torch.uint8\n",
      "model.layers.6.input_layernorm.weight torch.float32\n",
      "model.layers.6.post_attention_layernorm.weight torch.float32\n",
      "model.layers.7.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.7.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.7.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.7.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.7.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.7.mlp.up_proj.weight torch.uint8\n",
      "model.layers.7.mlp.down_proj.weight torch.uint8\n",
      "model.layers.7.input_layernorm.weight torch.float32\n",
      "model.layers.7.post_attention_layernorm.weight torch.float32\n",
      "model.layers.8.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.8.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.8.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.8.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.8.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.8.mlp.up_proj.weight torch.uint8\n",
      "model.layers.8.mlp.down_proj.weight torch.uint8\n",
      "model.layers.8.input_layernorm.weight torch.float32\n",
      "model.layers.8.post_attention_layernorm.weight torch.float32\n",
      "model.layers.9.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.9.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.9.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.9.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.9.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.9.mlp.up_proj.weight torch.uint8\n",
      "model.layers.9.mlp.down_proj.weight torch.uint8\n",
      "model.layers.9.input_layernorm.weight torch.float32\n",
      "model.layers.9.post_attention_layernorm.weight torch.float32\n",
      "model.layers.10.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.10.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.10.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.10.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.10.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.10.mlp.up_proj.weight torch.uint8\n",
      "model.layers.10.mlp.down_proj.weight torch.uint8\n",
      "model.layers.10.input_layernorm.weight torch.float32\n",
      "model.layers.10.post_attention_layernorm.weight torch.float32\n",
      "model.layers.11.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.11.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.11.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.11.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.11.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.11.mlp.up_proj.weight torch.uint8\n",
      "model.layers.11.mlp.down_proj.weight torch.uint8\n",
      "model.layers.11.input_layernorm.weight torch.float32\n",
      "model.layers.11.post_attention_layernorm.weight torch.float32\n",
      "model.layers.12.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.12.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.12.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.12.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.12.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.12.mlp.up_proj.weight torch.uint8\n",
      "model.layers.12.mlp.down_proj.weight torch.uint8\n",
      "model.layers.12.input_layernorm.weight torch.float32\n",
      "model.layers.12.post_attention_layernorm.weight torch.float32\n",
      "model.layers.13.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.13.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.13.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.13.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.13.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.13.mlp.up_proj.weight torch.uint8\n",
      "model.layers.13.mlp.down_proj.weight torch.uint8\n",
      "model.layers.13.input_layernorm.weight torch.float32\n",
      "model.layers.13.post_attention_layernorm.weight torch.float32\n",
      "model.layers.14.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.14.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.14.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.14.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.14.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.14.mlp.up_proj.weight torch.uint8\n",
      "model.layers.14.mlp.down_proj.weight torch.uint8\n",
      "model.layers.14.input_layernorm.weight torch.float32\n",
      "model.layers.14.post_attention_layernorm.weight torch.float32\n",
      "model.layers.15.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.15.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.15.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.15.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.15.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.15.mlp.up_proj.weight torch.uint8\n",
      "model.layers.15.mlp.down_proj.weight torch.uint8\n",
      "model.layers.15.input_layernorm.weight torch.float32\n",
      "model.layers.15.post_attention_layernorm.weight torch.float32\n",
      "model.layers.16.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.16.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.16.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.16.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.16.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.16.mlp.up_proj.weight torch.uint8\n",
      "model.layers.16.mlp.down_proj.weight torch.uint8\n",
      "model.layers.16.input_layernorm.weight torch.float32\n",
      "model.layers.16.post_attention_layernorm.weight torch.float32\n",
      "model.layers.17.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.17.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.17.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.17.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.17.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.17.mlp.up_proj.weight torch.uint8\n",
      "model.layers.17.mlp.down_proj.weight torch.uint8\n",
      "model.layers.17.input_layernorm.weight torch.float32\n",
      "model.layers.17.post_attention_layernorm.weight torch.float32\n",
      "model.layers.18.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.18.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.18.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.18.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.18.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.18.mlp.up_proj.weight torch.uint8\n",
      "model.layers.18.mlp.down_proj.weight torch.uint8\n",
      "model.layers.18.input_layernorm.weight torch.float32\n",
      "model.layers.18.post_attention_layernorm.weight torch.float32\n",
      "model.layers.19.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.19.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.19.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.19.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.19.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.19.mlp.up_proj.weight torch.uint8\n",
      "model.layers.19.mlp.down_proj.weight torch.uint8\n",
      "model.layers.19.input_layernorm.weight torch.float32\n",
      "model.layers.19.post_attention_layernorm.weight torch.float32\n",
      "model.layers.20.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.20.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.20.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.20.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.20.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.20.mlp.up_proj.weight torch.uint8\n",
      "model.layers.20.mlp.down_proj.weight torch.uint8\n",
      "model.layers.20.input_layernorm.weight torch.float32\n",
      "model.layers.20.post_attention_layernorm.weight torch.float32\n",
      "model.layers.21.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.21.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.21.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.21.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.21.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.21.mlp.up_proj.weight torch.uint8\n",
      "model.layers.21.mlp.down_proj.weight torch.uint8\n",
      "model.layers.21.input_layernorm.weight torch.float32\n",
      "model.layers.21.post_attention_layernorm.weight torch.float32\n",
      "model.layers.22.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.22.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.22.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.22.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.22.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.22.mlp.up_proj.weight torch.uint8\n",
      "model.layers.22.mlp.down_proj.weight torch.uint8\n",
      "model.layers.22.input_layernorm.weight torch.float32\n",
      "model.layers.22.post_attention_layernorm.weight torch.float32\n",
      "model.layers.23.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.23.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.23.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.23.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.23.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.23.mlp.up_proj.weight torch.uint8\n",
      "model.layers.23.mlp.down_proj.weight torch.uint8\n",
      "model.layers.23.input_layernorm.weight torch.float32\n",
      "model.layers.23.post_attention_layernorm.weight torch.float32\n",
      "model.layers.24.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.24.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.24.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.24.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.24.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.24.mlp.up_proj.weight torch.uint8\n",
      "model.layers.24.mlp.down_proj.weight torch.uint8\n",
      "model.layers.24.input_layernorm.weight torch.float32\n",
      "model.layers.24.post_attention_layernorm.weight torch.float32\n",
      "model.layers.25.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.25.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.25.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.25.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.25.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.25.mlp.up_proj.weight torch.uint8\n",
      "model.layers.25.mlp.down_proj.weight torch.uint8\n",
      "model.layers.25.input_layernorm.weight torch.float32\n",
      "model.layers.25.post_attention_layernorm.weight torch.float32\n",
      "model.layers.26.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.26.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.26.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.26.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.26.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.26.mlp.up_proj.weight torch.uint8\n",
      "model.layers.26.mlp.down_proj.weight torch.uint8\n",
      "model.layers.26.input_layernorm.weight torch.float32\n",
      "model.layers.26.post_attention_layernorm.weight torch.float32\n",
      "model.layers.27.self_attn.q_proj.weight torch.uint8\n",
      "model.layers.27.self_attn.k_proj.weight torch.uint8\n",
      "model.layers.27.self_attn.v_proj.weight torch.uint8\n",
      "model.layers.27.self_attn.o_proj.weight torch.uint8\n",
      "model.layers.27.mlp.gate_proj.weight torch.uint8\n",
      "model.layers.27.mlp.up_proj.weight torch.uint8\n",
      "model.layers.27.mlp.down_proj.weight torch.uint8\n",
      "model.layers.27.input_layernorm.weight torch.float32\n",
      "model.layers.27.post_attention_layernorm.weight torch.float32\n",
      "model.norm.weight torch.float32\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],param[1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 97,255,424 || all params: 3,310,005,248 || trainable%: 2.9382\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    inference_mode=False,\n",
    "    use_rslora=True,\n",
    "    init_lora_weights=\"gaussian\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.0.input_layernorm.weight False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.1.input_layernorm.weight False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.2.input_layernorm.weight False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.3.input_layernorm.weight False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.4.input_layernorm.weight False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.5.input_layernorm.weight False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.6.input_layernorm.weight False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.7.input_layernorm.weight False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.8.input_layernorm.weight False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.9.input_layernorm.weight False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.10.input_layernorm.weight False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.11.input_layernorm.weight False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.12.input_layernorm.weight False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.13.input_layernorm.weight False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.14.input_layernorm.weight False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.15.input_layernorm.weight False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.16.input_layernorm.weight False\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.17.input_layernorm.weight False\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.18.input_layernorm.weight False\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.19.input_layernorm.weight False\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.20.input_layernorm.weight False\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.21.input_layernorm.weight False\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.22.input_layernorm.weight False\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.23.input_layernorm.weight False\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.24.input_layernorm.weight False\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.25.input_layernorm.weight False\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.26.input_layernorm.weight False\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight False\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight False\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.27.input_layernorm.weight False\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight False\n",
      "base_model.model.model.norm.weight False\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = '''ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ପାଇଁ ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ର କିପରି ମିଳିମିଶି କାର୍ଯ୍ୟ କରିପାରିବେ?'''\n",
    "# answer = '''ଯେକୌଣସି ରାଜ୍ୟରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ପାଇଁ ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରର ମିଳିତ ପ୍ରୟାସର ଆବଶ୍ୟକତା ରହିଛି। ଓଡ଼ିଶାର ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ର ରାଜ୍ୟରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଲାଗି ଏକ ବିସ୍ତୃତ ରଣନୀତି ବିକଶିତ ଏବଂ କାର୍ଯ୍ୟକାରୀ କରିବା ଲାଗି ମିଳିତ ଭାବେ କାର୍ଯ୍ୟ କରିପାରିବେ।\n",
    "# ସରକାର ଘରୋଇ କ୍ଷେତ୍ର ସହିତ ମିଶି କାମ କରିବାର ଗୋଟିଏ ଉପାୟ ହେଲା ଘରୋଇ ନିବେଶ ପାଇଁ ଅନୁକୂଳ ବାତାବରଣ ସୃଷ୍ଟି କରିବା, ଏଥିରେ ଘରୋଇ କ୍ଷେତ୍ରର ଭାଗିଦାରୀକୁ ପ୍ରୋତ୍ସାହିତ କରିବା ପାଇଁ ଟିକସ ଏବଂ ନିୟାମକ ପ୍ରତିବନ୍ଧକକୁ ହ୍ରାସ କରିବା, ଏହା ବ୍ୟତୀତ ସରକାର ଟିକସ ରିହାତି, ସବସିଡି ଏବଂ ପର୍ଯ୍ୟଟନ ବିକାଶ ପ୍ରକଳ୍ପ ପାଇଁ ଜମି ଆଦି ପ୍ରୋତ୍ସାହନ ମଧ୍ୟ ପ୍ରଦାନ କରିପାରିବେ।\n",
    "# ଘରୋଇ କ୍ଷେତ୍ର ସହ ମିଶି ସରକାର ଘରୋଇ କ୍ଷେତ୍ର ସହ ମିଶି ନୂତନ ପର୍ଯ୍ୟଟନ ଉତ୍ପାଦ ପ୍ରସ୍ତୁତ କରିପାରିବେ ଯାହା ଉଭୟ ଘରୋଇ ଏବଂ ଅନ୍ତର୍ଜାତୀୟ ପର୍ଯ୍ୟଟକଙ୍କ ଆବଶ୍ୟକତା ପୂରଣ କରିପାରିବ।\n",
    "# ସରକାର ମଧ୍ୟ ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରର ଭାଗିଦାରୀକୁ ପ୍ରୋତ୍ସାହିତ କରିବା ପାଇଁ ପ୍ରଯୁକ୍ତିର ଉପଯୋଗ କରିପାରିବେ। ଉଦାହରଣ ସ୍ୱରୂପ, ସରକାର ପର୍ଯ୍ୟଟନ ସ୍ଥଳକୁ ପ୍ରୋତ୍ସାହିତ କରିବା ଏବଂ ସମ୍ଭାବ୍ୟ ପର୍ଯ୍ୟଟକମାନଙ୍କ ସହିତ ଯୋଡ଼ିବା ଲାଗି ସୋସିଆଲ ମିଡିଆ ପ୍ଲାଟଫର୍ମର ଉପଯୋଗ କରିପାରିବେ। ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନ ଆକର୍ଷଣ ଏବଂ ଅନୁଭବ ପ୍ରଦର୍ଶିତ କରିବା ଲାଗି ଏକ ଅନଲାଇନ ପ୍ଲାଟଫର୍ମ ପ୍ରତିଷ୍ଠା କରିବା ଦ୍ୱାରା ଅଧିକ ପର୍ଯ୍ୟଟକଙ୍କୁ ଆକର୍ଷିତ କରିବାରେ ସହାୟତା ମିଳିପାରିବ।\n",
    "# ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଲାଗି ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରକୁ ମିଳିତ ଭାବେ କାର୍ଯ୍ୟ କରିବାକୁ ପଡିବ ଯେପରିକି ପର୍ଯ୍ୟଟନ ଗତିବିଧି ଦ୍ୱାରା ପର୍ଯ୍ୟାବରଣର କ୍ଷୟ କିମ୍ବା ସ୍ଥାନୀୟ ସମ୍ପ୍ରଦାୟର କ୍ଷତି ନ ହେଉ।\n",
    "# ଶେଷରେ, ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରକୁ ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଲାଗି ଏକ ଅନୁକୂଳ ପରିବେଶ ସୃଷ୍ଟି କରିବା ଆବଶ୍ୟକ ଏବଂ ଏହା ସୁନିଶ୍ଚିତ କରିବା ଉଚିତ ଯେ ବିକାଶ ସ୍ଥାୟୀ ହେବ। ” ମିଳିତ ଭାବେ କାର୍ଯ୍ୟ କରି ସେମାନେ ପର୍ଯ୍ୟଟନ ରଣନୀତିକୁ ବିକଶିତ ଏବଂ କାର୍ଯ୍ୟକାରୀ କରିପାରିବେ ଯାହା କେବଳ ପର୍ଯ୍ୟଟନ ଉଦ୍ୟୋଗ ନୁହେଁ ବରଂ ସ୍ଥାନୀୟ ଗୋଷ୍ଠୀ ଏବଂ ପରିବେଶକୁ ମଧ୍ୟ ଲାଭାନ୍ୱିତ କରିବ।'''\n",
    "\n",
    "# tokenized_text = tokenizer(answer).input_ids\n",
    "# print(len(tokenized_text))\n",
    "# for idx in range(len(tokenized_text)):\n",
    "#     clear_output(wait=True)\n",
    "#     print(tokenizer.decode(tokenized_text[0:idx]))\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the LLAMA model on a single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nଆପଣଙ୍କ ନାଁ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nମୋ ନାଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଏବଂ ମୁଁ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଦ୍ୱାରା ବିକଶିତ ଏକ ଭାଷା ମଡେଲ।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nଆପଣଙ୍କ ନାଁ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ନାମକ ଏକ ଭାଷା ମଡେଲ୍ ଏବଂ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ହୋଇଛି।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nଆପଣଙ୍କ ନାଁ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nଆପଣ ମୋତେ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ବୋଲି ଡାକି ପାରିବେ ଏବଂ ମୁଁ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ଏକ ଭାଷା ମଡେଲ ଭାବେ ତାଲିମ ପାଇଛି।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nଆପଣ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଯାହାକି ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ଏକ ଭାଷା ମଡେଲ।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nନିଜ ବିଷୟରେ କୁହନ୍ତୁ।<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nଭାଷା ମଡେଲ ଭାବେ ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ନାମରେ ପରିଚିତ ଏବଂ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ତାଲିମ ପାଇଛି।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nଆପଣ କିଏ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nଭାଷା ମଡେଲ ଭାବେ ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ନାମରେ ପରିଚିତ ଏବଂ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ତାଲିମ ପାଇଛି।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nଆପଣ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nମୋ ନାଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଏବଂ ମୁଁ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଦ୍ୱାରା ବିକଶିତ ଏକ ଭାଷା ମଡେଲ।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>',\n",
       " '<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\nକିଏ ତୁମକୁ ବିକଶିତ କରିଛି?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nଆପଣ ମୋତେ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ବୋଲି ଡାକି ପାରିବେ ଏବଂ ମୁଁ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ଏକ ଭାଷା ମଡେଲ ଭାବେ ତାଲିମ ପାଇଛି।।<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "\n",
    "tokenizer.batch_decode(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eval(model,idx=5):\n",
    "    with model.disable_adapter():\n",
    "        model.config.use_cache = True\n",
    "        sample=dataset['train'][idx]\n",
    "        question=sample['instruction']\n",
    "        answer = sample['output']\n",
    "        chat_template = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "        inputs = tokenizer(chat_template , return_tensors=\"pt\").to(device)\n",
    "        # print(prompt)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                do_sample=False,\n",
    "                max_new_tokens=300,\n",
    "                repetition_penalty=1.3,\n",
    "                temperature=0.7,         # Optional: smooth randomness\n",
    "                top_k=50,                # Optional: top-k sampling\n",
    "                top_p=0.9                # Optional: nucleus sampling\n",
    "            )\n",
    "\n",
    "        processed_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '',\n",
       " 'english_input': '',\n",
       " 'english_instruction': 'Tell me about you.',\n",
       " 'instruction': 'ଆପଣଙ୍କ ବିଷୟରେ କୁହନ୍ତୁ।',\n",
       " 'output': 'ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଯାହାକି ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ଏକ ଭାଷା ମଡେଲ।',\n",
       " 'english_output': 'I am Olive a chatbot assistant, a language model trained by researchers from OdiaGenAI.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan.dash/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/mohan.dash/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଆପଣଙ୍କ ବିଷୟରେ କୁହନ୍ତୁ।<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\"ଦા, ଅ‌‍​ਮ ଚો-ല ଏ ଜ‌‍​ਗ ଡੀ ଫ‌‍​ਸ. \" (Dā am chō lă jg dī fos) - “The earth has enough for everyone's need but not so much that anyone would want to hoard it.”<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "pred = generate_eval(model=model,idx=40)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(128256, 3072)\n",
      "        (layers): ModuleList(\n",
      "          (0-27): 28 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
      "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with model.disable_adapter():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan.dash/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500, Loss: 0.3461\n",
      "Epoch 3/500, Loss: 0.3559\n",
      "Epoch 4/500, Loss: 0.3663\n",
      "Epoch 5/500, Loss: 0.3710\n",
      "Epoch 6/500, Loss: 0.3310\n",
      "Epoch 7/500, Loss: 0.3353\n",
      "Epoch 8/500, Loss: 0.3283\n",
      "Epoch 9/500, Loss: 0.3221\n",
      "Epoch 10/500, Loss: 0.1307\n",
      "Epoch 11/500, Loss: 0.1288\n",
      "Epoch 12/500, Loss: 0.1364\n",
      "Epoch 13/500, Loss: 0.1335\n",
      "Epoch 14/500, Loss: 0.0817\n",
      "Epoch 15/500, Loss: 0.0742\n",
      "Epoch 16/500, Loss: 0.0786\n",
      "Epoch 17/500, Loss: 0.0809\n",
      "Epoch 18/500, Loss: 0.0820\n",
      "Epoch 19/500, Loss: 0.0862\n",
      "Epoch 20/500, Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 6 ********************\n",
      "Predictions: <|begin_of_text|><|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଆପଣଙ୍କ ନାଁ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Meta AI ଏବଂ ଚିତ୍ର-ସମୂହ, ଯଥା ଗବେଷ୍ଟ ଅଲିଭ ଓଡିଆ. Meta AI ଦ୍ୱ�\n",
      "******************** end ********************\n",
      "Epoch 21/500, Loss: 0.0567\n",
      "Epoch 22/500, Loss: 0.0513\n",
      "Epoch 23/500, Loss: 0.0590\n",
      "Epoch 24/500, Loss: 0.0411\n",
      "Epoch 25/500, Loss: 0.0355\n",
      "Epoch 26/500, Loss: 0.0418\n",
      "Epoch 27/500, Loss: 0.0441\n",
      "Epoch 28/500, Loss: 0.0341\n",
      "Epoch 29/500, Loss: 0.0193\n",
      "Epoch 30/500, Loss: 0.0351\n",
      "Epoch 31/500, Loss: 0.0294\n",
      "Epoch 32/500, Loss: 0.0279\n",
      "Epoch 33/500, Loss: 0.0334\n",
      "Epoch 34/500, Loss: 0.0163\n",
      "Epoch 35/500, Loss: 0.0217\n",
      "Epoch 36/500, Loss: 0.0199\n",
      "Epoch 37/500, Loss: 0.0197\n",
      "Epoch 38/500, Loss: 0.0201\n",
      "Epoch 39/500, Loss: 0.0171\n",
      "Epoch 40/500, Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 12 ********************\n",
      "Predictions: <|begin_of_text|><|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଆପଣଙ୍କ ନାଁ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ମୋ ଅଲିବ୍ ଏକ ଚାଟ୍ବତ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଓଡିଆ-ଜେନ-�\n",
      "******************** end ********************\n",
      "Epoch 41/500, Loss: 0.0171\n",
      "Epoch 42/500, Loss: 0.0116\n",
      "Epoch 43/500, Loss: 0.0105\n",
      "Epoch 44/500, Loss: 0.0117\n",
      "Epoch 45/500, Loss: 0.0157\n",
      "Epoch 46/500, Loss: 0.0143\n",
      "Epoch 47/500, Loss: 0.0110\n",
      "Epoch 48/500, Loss: 0.0069\n",
      "Epoch 49/500, Loss: 0.0082\n",
      "Epoch 50/500, Loss: 0.0067\n",
      "Epoch 51/500, Loss: 0.0104\n",
      "Epoch 52/500, Loss: 0.0055\n",
      "Epoch 53/500, Loss: 0.0069\n",
      "Epoch 54/500, Loss: 0.0069\n",
      "Epoch 55/500, Loss: 0.0051\n",
      "Epoch 56/500, Loss: 0.0040\n",
      "Epoch 57/500, Loss: 0.0046\n",
      "Epoch 58/500, Loss: 0.0054\n",
      "Epoch 59/500, Loss: 0.0048\n",
      "Epoch 60/500, Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 4 ********************\n",
      "Predictions: <|begin_of_text|><|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଆପଣଙ୍କ ନାଁ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ମୋ ଅଲିଭ୍ ଏକ ବୁଦ୍ଧିଷ୍ଟ, ଓଂଶେନ ଚାଟ୍ବଟ୍ ଆସିଷ�\n",
      "******************** end ********************\n",
      "Epoch 61/500, Loss: 0.0042\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m gradient_accumulation_steps  \u001b[38;5;66;03m# Normalize loss\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m gradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "gradient_accumulation_steps = 4\n",
    "max_steps=500\n",
    "# Define optimizer\n",
    "optimizer = PagedAdam32bit(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_steps,\n",
    ")\n",
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "global_step= 0\n",
    "\n",
    "while global_step< max_steps:\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        model.config.use_cache = False\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'].to('cuda'), attention_mask=batch['attention_mask'].to('cuda'), labels=batch['labels'].to('cuda'))\n",
    "        loss = outputs.loss\n",
    "        loss = loss / gradient_accumulation_steps  # Normalize loss\n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        global_step += 1\n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "        \n",
    "        if global_step % 20 == 0:\n",
    "            pred = generate_eval()\n",
    "            print('*'*20,step+1,'*'*20)\n",
    "            print(\"Predictions:\", pred)\n",
    "            print('*'*20,'end','*'*20)\n",
    "            \n",
    "        \n",
    "        print(f\"Epoch {global_step + 1}/{max_steps}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('adapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/nas/buffer/mohan.dash/llama_3_finetuned/model_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/nas/buffer/mohan.dash/llama_3_finetuned/model_checkpoint.pt\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "    'global_step': global_step\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Checkpoint saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
