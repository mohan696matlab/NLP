J'ai fait des tests de comparaison pour Amjad sur la détection de WHEELS TIN en utilisant CycleOPS (ancien) et YOLOv11 (nouveau).
Les deux fonctionnent bien, mais YOLO est plus rapide car il utilise le GPU et son implémentation est plus simple.
Tests de détection d’anomalies sur les cas de Thales et le kit de Safran.
Les deux fonctionnent bien et l’étude de faisabilité est réussie.
J’essaie d’implémenter un modèle de crowd counting en utilisant la méthode diffusion.
Cette méthode pourrait être utile pour compter de petites particules (comme dans le cas d’usage Surceo).
Mais elle n’a pas donné de bons résultats.

Annotation des keypoints pour le fine-tuning de yolo-Pose.
Fine-tuning du modèle YOLO-Pose pour la détection des keypoints sur le "control dimension Votat". Les résultats n'étaient pas très bons, peut-être à cause du nombre limité d'échantillons (10 images).
Comparaison entre YOLO-Tin et Cyclops : les performances sont très similaires, mais le modèle YOLO-Tin est 4x plus rapide car il utilise le GPU.
Entraînement du modèle PatchCore pour deux cas d'utilisation de Thales.

Projet de Jérémie : Comptage de particules et estimation de taille → Entraînement d'un modèle de segmentation YOLO.
Annotation en cours pour la segmentation d’instances 
Test YOLO pour localisation des wheels TIN :
Modèle YOLO Nano entraîné sur Batilly & Douai.
mAP50 = 0.995, fonctionne bien.
Rapide : 30 ms/image (40 ms avec post-traitement TIN crop).
Création d’un Master dataset yolo :
4253 images train, 800 eval (toutes les roues sur NAS).
Modèle YOLO en cours d'entraînement. 


Travaillé sur le dataset d’anomaly detection de Thales pour diviser le composant en 3 zones différentes et détecter les anomalies séparément pour chaque zone.  
- Les résultats sont prometteurs, mais cela prend 3 fois plus de temps qu’un modèle unique.  

Appliqué PatchCore et Efficient AD sur le nouveau dataset reçu de Thales pour détecter des défauts de wafer. Résultat : 100% de précision, mais toutes les images NOK sont plus lumineuses que les OK, ce qui facilite trop la détection. Même la heatmap d’anomalie met l’accent sur la luminosité plutôt que sur les vraies anomalies.  

Travailler sur un nouveau projet avec Jaremie pour particle counting et l'estimation de taille pour Sourceo.
J'ai essayé la détection de contours, la segmentation par watershed, mais il est difficile d'isoler les particules quand elles sont en contact et la résolution de l’image n’est pas suffisante pour des particules aussi petites.
J’ai récemment essayé SAM2, mais ce n'était pas très efficace non plus. Je pense que le finetuning peut aider, mais je ne l’ai pas encore testé.
Implémentation de efficientAD pour le modèle de anomaly detection.

PatchCore testé sur 4 datasets PCB : >99% précision sur 2, mais <96% sur les autres.
SimpleNet testé, mais moins performant et plus lent que PatchCore.
Détection par diffusion possible alternative. 

Travailler sur un nouveau projet avec Jaremie pour particle counting et l'estimation de taille pour Sourceo.
J'ai essayé la détection de contours, la segmentation par watershed, mais il est difficile d'isoler les particules quand elles sont en contact et la résolution de l’image n’est pas suffisante pour des particules aussi petites.
J’ai récemment essayé SAM2, mais ce n'était pas très efficace non plus. Je pense que le finetuning peut aider, mais je ne l’ai pas encore testé.
Implémentation de efficientAD pour le modèle de anomaly detection.

PatchCore testé sur 4 datasets PCB : >99% précision sur 2, mais <96% sur les autres.
SimpleNet testé, mais moins performant et plus lent que PatchCore.
Détection par diffusion possible alternative. 

Génération de données synthétiques pour les wheels à l'aide de modèles de diffusion. Le modèle Tr-ocr a été entraîné uniquement sur ces images synthétiques, puis testé sur de réelle images TIN (résultats peu satisfaisants).
 
Le modèle a ensuite été entraîné en utilisant différentes combinaisons d'images synthétiques et réelles de TIN, mais les performances ne se sont pas beaucoup améliorées.
 
Travail sur le nouveau cas d'utilisation de détection d'anomalies de Thales.
 
L'entraînement et les tests de YOLOv11 pour la localisation des TIN ont donné les meilleurs résultats avec une taille d'image de 1280x1280 pixels.

Création d'un master dataset pour les Wheels en combinant 4 cas d'utilisation différents (maintenant présent dans le NAS).
 
Utilisation de ce master dataset pour évaluer les performances de tr-ocr et d'autres SOTA modèles de classification . Le modèle OCR est plus précis.
 
Expérimentation avec l'entraînement LoRA pour Tr-OCR.
 
Tâche pour la semaine prochaine : création d'un modèle Master OCR  pour les wheels, en utilisant des images générées par diffusion.

- Fine-tuning et évaluation de Tr-OCR sur différents cas d'utilisation (Batilly, Sandouville, Tanger, Pitesti).  
- Présentation des résultats à Cyril.  
- Étude d'ablation concernant :  
  - Les différentes versions du modèle.  
  - Le nombre minimum d'échantillons requis.  
  - Le meilleur learning rate.  
  - Le nombre d'étapes nécessaires pour faire converger la loss. 

- Expérience avec un modèle OCR pour le cas des wheels.  Le modèle s'appelle Tr-OCR (Microsoft).  
- J'ai expérimenté avec les versions small, base et large du modèle, et la performance est impressionnante.  
- Ce model a une performance supérieure comparée au modèle de classification.  
- Testé ce modèle sur 2 cas : Batilly et Tanger. Fonctionne bien pour les deux cas.  
- Présentation préparée pour la réunion du 6 janvier.  

1. Étude de la lib cyclops pour le pipeline d'inférence.  
2. Entraînement d'un nouveau modèle de classification pour le cas des wheels batilly avec Bogdan :  
   - Expérimentations avec des augmentations d'images.  
   - Les meilleurs résultats obtenus se situent entre 85% - 87%.  
 
3. Travail en cours sur le modèle TrOCR pour la classification :  
   - Ces modèles sont déjà entraînés sur des données de texte imprimé.  
   - Ils sont susceptibles de mieux fonctionner qu'un modèle pré-entraîné sur ImageNet.

Toujours en train de travailler sur la diffusion avec les données des WHEELS.
- Les images générées sont maintenant très cohérentes.
- Utilisation d'un classifier (ViT) pour entraîner sur les images générées et évaluer sur les images réelles.
- Reçu les données pour le cas des wheels Tanger aujourd'hui.
- Début du travail pour obtenir les crops à partir des annotations.
-> Entraîner un modèle de diffusion -> Générer des données synthétiques -> Entraîner un classifier -> Évaluer sur des données réelles.

- Affiner davantage les modèles sur les données WHEELS en utilisant les modèles Stable Diffusion.  
- La méthode de diffusion en double étape semble donner des résultats cohérents et fidèles au texte donné.  
- Étudier les nouveaux modèles de state-of-the-art pour la détection d'anomalie.

Plus de travail sur diffusion avec les roues, quelques problèmes identifiés :
Absence d'information pour le TIN exact pour chaque image.
Le aspect ratio des crops peut ne pas être idéal pour diffusion.
Variabilité dans le type et la taille de la font.
Les résultats initiaux sont prometteurs, mais plus de travail est nécessaire.
 
 
Travail sur le nouveau cas d'utilisation avec Sofiane pour la détection d'anomalies.
Application de Patchcore et EfficientAD.
Le modèle Patchcore avec une résolution de 1024x1024 semble donner les meilleurs résultats pour la segmentation.

- Finetuning de SD1.5 sur OP250 et édition avec SAM (ça fonctionne bien).  
- Test d’un nouveau cas d’usage : génération de données synthétiques pour OCR avec les données de wheels. Beaucoup de problèmes rencontrés :  
  - Le texte sur les wheels est courbé, donc difficile de générer une image guide avec les glyphes pour la diffusion.  
  - Les captions ne sont pas disponibles pour le texte complet.  

1. Fine-tuning du modèle Stable Diffusion XL  sur différents cas d’utilisation pour la génération de micro-percussion.  
2. Utilisation de  ControlNet  pour guider la génération, avec des approches similaires à cela.  
 
 
3. Étude de l’effet de différents paramètres sur la qualité de génération.  
4. Création de présentations sur ce sujet.  
5. Revue de littérature sur la génération de texte basée sur la diffusion sur une image.  

"Fine-tuning" du modèle "Stable Diffusion" pour différents cas d'usage, comme "amortisseur" et "vis-gauche", avec des résultats prometteurs.
Besoin seulement de 10-20 images et 20-30 minutes d'entraînement.
Les images générées sont en 1024*1024, donc sans perte d'information.
La génération d’images est lente et nécessite une grande "V-RAM".
Application de "Stable Diffusion" pour la génération de micro-percussion avec des "text prompts" et un "fine-tuning" "LoRA" avec Ismail. Les premiers résultats sont prometteurs.
Modification de la détection de contamination pour le "POC-4".
Préparation d'une présentation pour "R-News".

Application de "SAM+diffusion" sur "vis gauche" pour évaluer la générabilité. Ça fonctionne bien.
Expérience avec le fine-tuning du modèle "Stable Diffusion XL" avec très peu d'exemples, en utilisant "Parameter Efficient Fine Tuning", quelques résultats.
Entraînement complet d'un modèle "Unet" plus petit sur notre dataset (fonctionne bien avec moins de calculs et un entraînement plus rapide).

Étude d'un Parameter Efficient Finetuning aux modèles de diffusion.
 
Résultat : Ce n'est pas très efficace ; prend le même temps que "full finetuning", mais nécessite moins d'espace de stockage et moins de mémoire VRAM.

Entraînement d’un nouveau modèle "tiny-diffusion" depuis zéro (not pre-trained).
 
Après 60 000 étapes, les résultats ne sont pas très satisfaisants.
Nous continuons l’entraînement pour plus d'étapes dans l'espoir d'obtenir de meilleurs résultats.

- Utilisation du modèle SAM-2 pour la génération automatique de masques.
- Combinaison Diffusion + SAM-2 = bons résultats. 
- Création d'un dataset synthétique pour amortisseur avec diffusion-editing.
- Étude du Parameter Efficient Finetuning (PEFT) pour les modèles de diffusion.

1. Revue de la littérature sur l'édition d'images basée sur la stable diffusion (4 articles principaux) et création d'une présentation, avec application sur notre jeu de données.
 
2. Quelques domaines clés de recherche : amélioration de la qualité d'image avec la diffusion latente, entraînement d'un modèle de diffusion pour la tâche d'inpainting, étude de la "dis-entanglement"diffusion pour la génération d'images nouvelles.

1. Preparation du dataset pour entrainment de stable diffusion sur le donne du Amortisseur
 
2. Etude- cross attention based mask generation, pour plus generalize le création de mask dan notre use case.

Débogage du code pour POC-4 sur le suivi de contamination, avec un entraînement du modèle YOLOv8 utilisant ByteTrack, qui a donné des résultats insatisfaisants en raison d'identifiants de suivi inconsistants. 
 
Après avoir exploré des méthodes alternatives comme le suivi IOU, le suivi par centroides et le filtre de Kalman, une combinaison de suivi par centroides et IOU a montré les meilleures performances. 
 
L'algorithme de suivi a été mis à jour pour éviter le multiple comptage du même objet
 
Nous nous concentrons maintenant sur l'entraînement d'un modèle de diffusion avec des txt prompts pour le cas amortisseur.

Utilisation du modèle de diffusion pour le jeu de données Thales POC 2  
Débogage de mon propre code pour l'estimation de la contamination, Thales  
Entraînement d'un nouveau modèle de diffusion avec des images haute résolution pour préserver les détails et utilisation de techniques de masquage avancées.

revue de la littérature pour « Semantic Latent Directions in Diffusion Models ». Comment découvrir automatiquement les fonctionnalités latentes dans Diffusion.
application de la diffusion pour le cas de l'amortissement.
application de la diffusion pour Thales (cas de données faibles).
présentation pour la réunion hebdomadaire de GenAI

Le temps d'inférence a été amélioré grâce à SuperGlue, même si les masques générés n'étaient pas entièrement précis. Par conséquent, les travaux ont commencé sur une nouvelle méthode permettant de générer automatiquement ces masques en utilisant le modèle de diffusion lui-même. Cette nouvelle approche produit des masques sémantiquement meilleurs et reste compétitive en termes de temps d'inférence.
 
 
La littérature sur l'édition d'images basée sur la diffusion et l'estimation de la dimensionnalité intrinsèque des images est en cours de révision.
 
 
 
Une présentation est en préparation pour le Gen AI Point.

Remédier au déséquilibre des classes dans le modèle de diffusion
 
Pour gérer le déséquilibre des classes dans le modèle de diffusion, nous oversample les échantillons NOK, garantissant que chaque itération reçoit un nombre égal d'échantillons OK et NOK. Cela permet au modèle de diffusion de générer des images OK et NOK avec précision en fonction des étiquettes de classe données.
 
Améliorer la génération d'images avec Guidance
 
L'objectif suivant était de générer des images dans des conditions d'éclairage spécifiques en utilisant une technique appelée « Guidance». Si l’approche initiale, qui utilisait MAE, fonctionnait bien, les images générées manquaient de diversité.
 
Pour améliorer cela, nous avons décidé de guider le processus en utilisant l'histogramme des couleurs de l'image. Cependant, le défi était que l’histogramme n’est pas différentiable, ce qui signifie qu’il ne peut pas être utilisé pour la back-propagation. Pour résoudre ce problème, nous avons développé une version différentiable de l'histogramme en utilisant une kernel fonction. Cette nouvelle méthode a non seulement mieux fonctionné, mais a également préservé la diversité des images générées.

Benchmarking
Comparaison de l'efficacité d'Efficient AD et de PatchCore sous différentes lumières, avec et sans taches jaunes. Efficient AD est plus robuste.
Suivi de la contamination
Suivi du comptage et estimation de la zone contaminée avec classification sur la vidéo. J'utilise un simple suivi de centroides avec la distance euclidienne et ça fonctionne bien.
Sauvegarde et téléchargement
Mettre tous les POC 4 de Thales sur le NAS et les télécharger sur GitLab.

U2-Net entraîné sur des données synthétiques n'est pas capable de se généraliser au cas d'utilisation.
- Ajouté des échantillons du cas d'utilisation avec les données synthétiques pour réentraîner U2-Net, mais les résultats ont été décevants.
- Delphine a obtenu de très bons résultats avec YOLOv8 sur le même dataset, montrant une meilleure généralisation.
- Travaillé sur le comptage et la catégorisation des contaminations dans les vidéos, nécessitant un algorithme de tracking pour éviter les doubles comptages.
- Actuellement, l'utilisation de la distance Euclidienne pour le tracking fonctionne bien, mais une méthode plus complète pourrait être nécessaire à l'avenir.

Détection de contamination des écrans Thales
 
Configuration d'une métrique d'évaluation
 
Évaluation de efficientAD et de PatchCore sur le même ensemble de données
 
Préparation de la présentation pour la réunion avec Thales

Thales POC3 s'est concentré sur la détection des scratches à l'aide de PatchCore :
  1. Développement d'un algorithme pour maintenir de manière cohérente l'alignement de l'écran dans le cadre.
  2. Obtention de résultats satisfaisants grâce à l'algorithme mis en œuvre.
 
Thales POC4 visant à détecter et estimer la contamination par des poussières sur un écran :
  1. Formation d'un modèle de détection d'anomalies pour identifier les particules de poussière.
  2. Conception d'un algorithme pour catégoriser la contamination en fonction de la taille des particules.

1. Améliorer la qualité de la génération :
   - Création d'un modèle de guidage sans classifier utilisant la diffusion latent.
   - Passage à un modèle pré-entraîné après l'échec du modèle de base.
 
2. Détection des scratch sur l'écran Thales :
   - Utilisation de la détection d'anomalies.
   - Face à des difficultés de sélection d'une zone d'évaluation en raison d'une caméra non fixée.