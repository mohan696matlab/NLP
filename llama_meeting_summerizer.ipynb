{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the Hugging Face Transformers library, which gives us access to state-of-the-art speech and language models. If you haven’t installed it yet, run:\n",
    "\n",
    "```\n",
    "pip install transformers torch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s import the necessary libraries and set up our device for computation. If you have a GPU, the code will automatically use it for better performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing mp3 file to numpy requires the FFmpeg. Follow the steps in this link to have it installed. [(How to install FFmpeg in windows)](https://www.wikihow.com/Install-FFmpeg-on-Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline,AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPEECH-TO-TEXT WITH WHISPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll use OpenAI’s Whisper model to transcribe an audio file. We’re using the whisper-small model for efficiency, but you can switch to whisper-large for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe  = pipeline(\"automatic-speech-recognition\",\n",
    "                    \"openai/whisper-small\", \n",
    "                    chunk_length_s=30,\n",
    "                    stride_length_s=5,\n",
    "                    return_timestamps=True,\n",
    "                    device=device, \n",
    "                    generate_kwargs = {\"language\": 'Hindi', \"task\": \"translate\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s process an audio file. The model will transcribe and translate it into English.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan.dash/miniconda3/envs/diffuser_data_generation/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=translate, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=translate.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 5.5)--> Do you think India will grow at the speed with China growth?\n",
      "(5.5, 2.0)--> I don't think China grew at the speed that it grew. I think it has a lot of data. I am pretty sure they didn't grow at the rate that they grew because had they done so then they wouldn't have had the range of social and economic problems they are currently facing. They say that in the 70s, India and China were the same.\n",
      "(2.0, 5.0)--> And now today, look at China's economy versus India's economy.\n",
      "(5.0, 46.48)--> So, look at China's economy versus India's economy. So, people have definitely grown up. People say a lot. What people don't realise is that the British ravaged India to a greater extent than they ravaged East Asia, Southeast Asia.\n",
      "(51.48, 52.92)--> And therefore the journey that India had to traverse through the 50s and 60s was a far more demanding journey.\n",
      "(53.56, 56.84)--> It is through the Deng shopping opened up China in 78-79.\n",
      "(56.84, 60.4)--> And obviously they benefited from the liberalization and, you know,\n",
      "(60.4, 64.4)--> all credit to the Chinese Communist leadership for embracing the free market model.\n",
      "(64.4, 110.36)--> Right. One of the most radical jumps in thoughtorns that I have seen in my life. But I think the journey that we have traveled since 91, since 91 from the day we opened up, from then till now, if you look at the data, no country in the world has actually grown faster than us not even china not even china on a on a. I think per capita China is a little ahead. But 91 to now, what we have pulled off is pretty remarkable. And remember we have done this against severe odds in terms of going into that 91 period at a lower per capita income than China went into at 78. So, yes, China and us in the 70s were same and then they took off. But, Changa's model has frailties that I think our model doesn't have and TN9NG's very good\n",
      "(110.36, 267.76)--> book is Totoist vs Hair. I think while some people might think we are the Totoist. 4 years ago everyone said that Totoist is completely ruined. China used to do China-China. In the last 4-5 years China's economy has gone a little bad. It's a's a little bit smart. Their achievements are remarkable, especially on the technology front. For a country in the space of one generation to catch up with the west on technology is remarkable. But by the same token, our achievements on both the IT services front and the cultural front are remarkable. Don't underestimate the power of the fact that a lot of their identity, they have assimilated with the West. And I still don't fully understand why it was so ancient. How come they gave up their apparel, this clothing, their design for Western designs? I don't fully understand. We've held on to that and it will, Indio course, help us. How do you help? If you maintain identity, right? Identities at the core of a lot of human human civilizations also identities at the core of your belief system. Right? Because when under duress, in your people's darkest hours, you go back to your identity. If you're if a civilization, if a country, if a people can hold on to their identity, I think it says a lot about the way in which they can operate in the in the wide world, right? So why who I don't understand, I'm sure that our anthropologists have looked into this. Maybe the cultural revolution of Mao, the China's revolution, had some kind of identity. That is the first chance they said, let's go to our own clothes, let's westernize. We haven't done that. And I think that has implications for our future. More importantly, the financial system has been destroyed by us. Their environmental degradation is both unquantified and legendary and whilst we mourn about air pollution, my reading is that the polluted soil and water to extend in China that we don't think we have yet done. So there are different dimensions to this. Kudos to\n",
      "(267.76, 275.52)--> the Communist Party in China for embracing free market. We've done a reasonable job. We can do\n",
      "(275.52, 281.04)--> much better. But especially if you focus on Peninsular India. Thank you so much for watching this\n",
      "(281.04, 285.6)--> clip till the end. If you want to see more such clips, then subscribe to the Rajshamani\n",
      "(285.6, 287.2)--> Clips channel.\n"
     ]
    }
   ],
   "source": [
    "transcription = pipe(\"hindi_english_podcast.mp3\" )\n",
    "#Once the transcription is complete, we’ll format the text with timestamps for better readability.\n",
    "formatted_lyrics = \"\"\n",
    "for line in transcription['chunks']:\n",
    "    text = line[\"text\"]\n",
    "    ts = line[\"timestamp\"]\n",
    "    formatted_lyrics += f\"{ts}-->{text}\\n\"\n",
    "\n",
    "print(formatted_lyrics.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved to transcription.txt\n"
     ]
    }
   ],
   "source": [
    "# Let’s also save the transcription to a text file so we can use it later!\"\n",
    "with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(formatted_lyrics.strip())\n",
    "\n",
    "print(\"Transcription saved to transcription.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARIZING WITH LLAMA\n",
    "Now, let’s take it a step further! We’ll use Meta’s LLaMA model to summarize the transcript. For this, we need the Llama-3.2-3B-Instruct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295e4a72a5f6400e854bba5d4e43ce96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define a conversation prompt instructing LLaMA to summarize the meeting transcript in simple English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "\n",
      "**Meeting Minutes**\n",
      "\n",
      "**Attendees:** N/A\n",
      "\n",
      "**Date:** N/A\n",
      "\n",
      "**Topic:** India's Economic Growth and Comparison with China\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "1. The speaker discusses the economic growth of India and China, stating that India's growth has been remarkable despite facing severe odds, including a lower per capita income when India opened up in 1991.\n",
      "2. The speaker highlights the differences between India and China's economic models, noting that China's model has frailties that India's model does not have.\n",
      "3. The speaker praises China's achievements in technology, but notes that India's achievements in IT services and cultural identity are also significant.\n",
      "4. The speaker questions why China was able to assimilate with the West so quickly, and attributes this to the Cultural Revolution and the Chinese Communist Party's decision to westernize.\n",
      "5. The speaker emphasizes the importance of holding onto one's identity and cultural heritage, citing this as a key factor in a country's success.\n",
      "6. The speaker criticizes India's financial system for being destroyed, and notes that environmental degradation in China is a significant concern.\n",
      "7. The speaker concludes that India can do better and praises the Communist Party in China for embracing free market principles.\n",
      "\n",
      "**Action Items:** None\n",
      "\n",
      "**Next Steps:** N/A\n",
      "\n",
      "**Conclusion:** The meeting discussed India's economic growth and comparison with China, highlighting the differences between their economic models and the importance of cultural identity in a country's success.\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": ''' Write the minutes of this meeting transcript in simple and precise English.'''},\n",
    "    {\"role\": \"user\", \"content\": f'''{formatted_lyrics.strip()}'''},\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(conversation, tokenize=False)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "# print(prompt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=1000\n",
    "    )\n",
    "\n",
    "processed_text = tokenizer.decode(output[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "print(processed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser_data_generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
