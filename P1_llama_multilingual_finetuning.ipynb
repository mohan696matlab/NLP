{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608235252d8246f39a992d1437b1cdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095.841064453125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a Multi Lingual Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "# dataset = load_dataset(\"OdiaGenAI/hardcode_odia_qa_105\")\n",
    "dataset = load_dataset('OdiaGenAI/odia_domain_context_train_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'ଓଡ଼ିଶାର ଉଦୟଗିରି ଏବଂ ଖଣ୍ଡଗିରି ଗୁମ୍ଫାର ଇତିହାସ କ’ଣ?',\n",
       " 'input': '',\n",
       " 'output': 'ଉଦୟଗିରି ଏବଂ ଖଣ୍ଡଗିରି ଗୁମ୍ଫା ଭାରତର ଓଡ଼ିଶା ରାଜ୍ୟରେ ଅବସ୍ଥିତ ପ୍ରାଚୀନ ଗୁମ୍ଫା ପରିସରର ଏକ ସମୂହ। ଏହି ଗୁମ୍ଫା ଗୁଡିକ ଖ୍ରୀଷ୍ଟପୂର୍ବ ଦ୍ୱିତୀୟ ଶତାବ୍ଦୀ ଏବଂ ପ୍ରଥମ ଶତାବ୍ଦୀ ମଧ୍ୟରେ ଜୈନ ସନ୍ନ୍ୟାସୀମାନଙ୍କ ଦ୍ୱାରା ବାଲୁକା ପଥରରେ ଖୋଦିତ ହୋଇଥିବା ଜଣାଯାଏ।\\nଉଦୟଗିରି ଗୁମ୍ଫା ଗୁଡିକ ବୃହତ ଏବଂ ଅଧିକ ଜଟିଳ ହୋଇଥିବାବେଳେ ଖଣ୍ଡଗିରି ଗୁମ୍ଫା ଗୁଡିକ ଛୋଟ ଏବଂ ଡିଜାଇନ ଦୃଷ୍ଟିରୁ ସରଳ। ଏହି ପ୍ରାଚୀନ ଗୁମ୍ଫା ଗୁଡିକ ପ୍ରାଚୀନ ଭାରତୀୟ ସଭ୍ୟତାର ସ୍ଥାପତ୍ୟ କୌଶଳ ଏବଂ କଳାତ୍ମକ ଶ୍ରେଷ୍ଠତାର ପ୍ରମାଣ।\\nବିଗତ ବର୍ଷମାନଙ୍କରେ ଏହି ଗୁମ୍ଫା ସାରା ବିଶ୍ୱରୁ ପର୍ଯ୍ୟଟକଙ୍କ ଆକର୍ଷଣ କେନ୍ଦ୍ର ପାଲଟିଛି ଏବଂ ଭାରତୀୟ ପ୍ରତ୍ନତାତ୍ୱିକ ସର୍ବେକ୍ଷଣ ଦ୍ୱାରା ସଂରକ୍ଷିତ ହୋଇଛି। ଭାରତର ସମୃଦ୍ଧ ସାଂସ୍କୃତିକ ଐତିହ୍ୟ ପ୍ରତି ଆଗ୍ରହୀ ଯେକୌଣସି ବ୍ୟକ୍ତି ଏହି ଗୁମ୍ଫାକୁ ଦେଖିବା ଉଚିତ।'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lengths = [len(tokenizer(example['output'])['input_ids']) for example in dataset['train']]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Histogram of Tokenized Output Lengths\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Object for Pytorch-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset\n",
    "class LlamaDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        question=sample['instruction']\n",
    "        answer = sample['output']\n",
    "        prompt = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "        full_text = prompt+f'''{answer}<|eot_id|>'''\n",
    "\n",
    "        tokenized = tokenizer(full_text, truncation=True, add_special_tokens=False, padding=\"max_length\", max_length=1000)\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "        # Tokenize just the prompt to get the split point\n",
    "        prompt_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "        answer_start = len(prompt_ids)\n",
    "\n",
    "        # Mask everything before answer_start\n",
    "        labels = [-100] * answer_start + input_ids[answer_start:]\n",
    "        # Mask out padding as well\n",
    "        labels = [\n",
    "            label if token != tokenizer.pad_token_id else -100\n",
    "            for label, token in zip(labels, input_ids)\n",
    "        ]\n",
    "    \n",
    "        return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"attention_mask\": torch.tensor(attention_mask),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LlamaDataset(dataset['train'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.0.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.0.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.0.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.1.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.1.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.1.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.2.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.2.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.2.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.3.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.3.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.3.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.4.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.4.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.4.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.5.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.5.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.5.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.6.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.6.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.6.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.7.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.7.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.7.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.8.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.8.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.8.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.9.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.9.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.9.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.10.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.10.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.10.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.11.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.11.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.11.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.12.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.12.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.12.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.13.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.13.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.13.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.14.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.14.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.14.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.15.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.15.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.15.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.16.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.16.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.16.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.17.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.17.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.17.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.18.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.18.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.18.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.19.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.19.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.19.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.20.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.20.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.20.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.21.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.21.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.21.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.22.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.22.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.22.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.23.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.23.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.23.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.24.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.24.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.24.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.25.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.25.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.25.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.26.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.26.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.26.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.27.self_attn.q_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.self_attn.k_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.self_attn.v_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.self_attn.o_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.mlp.gate_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.mlp.up_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.mlp.down_proj.weight  dtype: torch.uint8  requirs grad:  False\n",
      "model.layers.27.input_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.layers.27.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  True\n",
      "model.norm.weight  dtype: torch.float16  requirs grad:  True\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of `prepare_model_for_kbit_training`\n",
    "\n",
    "When you load a model in 4-bit or 8-bit precision using bitsandbytes, some layers (like LayerNorm) still remain in full precision (float32), and certain operations (like weight updates) can be unstable or incompatible if done blindly on quantized weights.\n",
    "\n",
    "- Casts `LayerNorm` layers to `float32`\n",
    "- Sets `requires_grad=False` for all model parameters\n",
    "- Wraps the output layer (like `lm_head`) in `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.is_gradient_checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, 'adapter', is_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.is_gradient_checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = LoraConfig(\n",
    "#     r=64,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     inference_mode=False,\n",
    "#     use_rslora=True,\n",
    "#     init_lora_weights=\"gaussian\",\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = '''ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ପାଇଁ ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ର କିପରି ମିଳିମିଶି କାର୍ଯ୍ୟ କରିପାରିବେ?'''\n",
    "# answer = '''ଯେକୌଣସି ରାଜ୍ୟରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ପାଇଁ ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରର ମିଳିତ ପ୍ରୟାସର ଆବଶ୍ୟକତା ରହିଛି। ଓଡ଼ିଶାର ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ର ରାଜ୍ୟରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଲାଗି ଏକ ବିସ୍ତୃତ ରଣନୀତି ବିକଶିତ ଏବଂ କାର୍ଯ୍ୟକାରୀ କରିବା ଲାଗି ମିଳିତ ଭାବେ କାର୍ଯ୍ୟ କରିପାରିବେ।\n",
    "# ସରକାର ଘରୋଇ କ୍ଷେତ୍ର ସହିତ ମିଶି କାମ କରିବାର ଗୋଟିଏ ଉପାୟ ହେଲା ଘରୋଇ ନିବେଶ ପାଇଁ ଅନୁକୂଳ ବାତାବରଣ ସୃଷ୍ଟି କରିବା, ଏଥିରେ ଘରୋଇ କ୍ଷେତ୍ରର ଭାଗିଦାରୀକୁ ପ୍ରୋତ୍ସାହିତ କରିବା ପାଇଁ ଟିକସ ଏବଂ ନିୟାମକ ପ୍ରତିବନ୍ଧକକୁ ହ୍ରାସ କରିବା, ଏହା ବ୍ୟତୀତ ସରକାର ଟିକସ ରିହାତି, ସବସିଡି ଏବଂ ପର୍ଯ୍ୟଟନ ବିକାଶ ପ୍ରକଳ୍ପ ପାଇଁ ଜମି ଆଦି ପ୍ରୋତ୍ସାହନ ମଧ୍ୟ ପ୍ରଦାନ କରିପାରିବେ।\n",
    "# ଘରୋଇ କ୍ଷେତ୍ର ସହ ମିଶି ସରକାର ଘରୋଇ କ୍ଷେତ୍ର ସହ ମିଶି ନୂତନ ପର୍ଯ୍ୟଟନ ଉତ୍ପାଦ ପ୍ରସ୍ତୁତ କରିପାରିବେ ଯାହା ଉଭୟ ଘରୋଇ ଏବଂ ଅନ୍ତର୍ଜାତୀୟ ପର୍ଯ୍ୟଟକଙ୍କ ଆବଶ୍ୟକତା ପୂରଣ କରିପାରିବ।\n",
    "# ସରକାର ମଧ୍ୟ ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରର ଭାଗିଦାରୀକୁ ପ୍ରୋତ୍ସାହିତ କରିବା ପାଇଁ ପ୍ରଯୁକ୍ତିର ଉପଯୋଗ କରିପାରିବେ। ଉଦାହରଣ ସ୍ୱରୂପ, ସରକାର ପର୍ଯ୍ୟଟନ ସ୍ଥଳକୁ ପ୍ରୋତ୍ସାହିତ କରିବା ଏବଂ ସମ୍ଭାବ୍ୟ ପର୍ଯ୍ୟଟକମାନଙ୍କ ସହିତ ଯୋଡ଼ିବା ଲାଗି ସୋସିଆଲ ମିଡିଆ ପ୍ଲାଟଫର୍ମର ଉପଯୋଗ କରିପାରିବେ। ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନ ଆକର୍ଷଣ ଏବଂ ଅନୁଭବ ପ୍ରଦର୍ଶିତ କରିବା ଲାଗି ଏକ ଅନଲାଇନ ପ୍ଲାଟଫର୍ମ ପ୍ରତିଷ୍ଠା କରିବା ଦ୍ୱାରା ଅଧିକ ପର୍ଯ୍ୟଟକଙ୍କୁ ଆକର୍ଷିତ କରିବାରେ ସହାୟତା ମିଳିପାରିବ।\n",
    "# ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଲାଗି ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରକୁ ମିଳିତ ଭାବେ କାର୍ଯ୍ୟ କରିବାକୁ ପଡିବ ଯେପରିକି ପର୍ଯ୍ୟଟନ ଗତିବିଧି ଦ୍ୱାରା ପର୍ଯ୍ୟାବରଣର କ୍ଷୟ କିମ୍ବା ସ୍ଥାନୀୟ ସମ୍ପ୍ରଦାୟର କ୍ଷତି ନ ହେଉ।\n",
    "# ଶେଷରେ, ସରକାରୀ ଏବଂ ଘରୋଇ କ୍ଷେତ୍ରକୁ ଓଡ଼ିଶାରେ ପର୍ଯ୍ୟଟନକୁ ପ୍ରୋତ୍ସାହନ ଦେବା ଲାଗି ଏକ ଅନୁକୂଳ ପରିବେଶ ସୃଷ୍ଟି କରିବା ଆବଶ୍ୟକ ଏବଂ ଏହା ସୁନିଶ୍ଚିତ କରିବା ଉଚିତ ଯେ ବିକାଶ ସ୍ଥାୟୀ ହେବ। ” ମିଳିତ ଭାବେ କାର୍ଯ୍ୟ କରି ସେମାନେ ପର୍ଯ୍ୟଟନ ରଣନୀତିକୁ ବିକଶିତ ଏବଂ କାର୍ଯ୍ୟକାରୀ କରିପାରିବେ ଯାହା କେବଳ ପର୍ଯ୍ୟଟନ ଉଦ୍ୟୋଗ ନୁହେଁ ବରଂ ସ୍ଥାନୀୟ ଗୋଷ୍ଠୀ ଏବଂ ପରିବେଶକୁ ମଧ୍ୟ ଲାଭାନ୍ୱିତ କରିବ।'''\n",
    "\n",
    "# tokenized_text = tokenizer(answer).input_ids\n",
    "# print(len(tokenized_text))\n",
    "# for idx in range(len(tokenized_text)):\n",
    "#     clear_output(wait=True)\n",
    "#     print(tokenizer.decode(tokenized_text[0:idx]))\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the LLAMA model on a single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "\n",
    "tokenizer.batch_decode(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eval(model,idx=5,disable_lora=False):\n",
    "    \n",
    "    model.config.use_cache = True\n",
    "    sample=dataset['train'][idx]\n",
    "    question=sample['instruction']\n",
    "    answer = sample['output']\n",
    "    chat_template = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "    inputs = tokenizer(chat_template , return_tensors=\"pt\").to(device)\n",
    "    # print(prompt)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    if disable_lora:\n",
    "        with model.disable_adapter():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                max_new_tokens=512,\n",
    "                repetition_penalty=1.3,\n",
    "                temperature=0.7,         # Optional: smooth randomness\n",
    "                top_k=50,                # Optional: top-k sampling\n",
    "                top_p=0.9                # Optional: nucleus sampling\n",
    "            )\n",
    "    else:\n",
    "        output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        repetition_penalty=1.3,\n",
    "        temperature=0.7,         # Optional: smooth randomness\n",
    "        top_k=50,                # Optional: top-k sampling\n",
    "        top_p=0.9                # Optional: nucleus sampling\n",
    "        )\n",
    "\n",
    "    processed_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = generate_eval(model=model,idx=40,disable_lora=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "gradient_accumulation_steps = 4\n",
    "max_steps=500\n",
    "max_loss = 1e9\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = PagedAdam32bit(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=max_steps,\n",
    ")\n",
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "global_step= 0\n",
    "\n",
    "while global_step< max_steps:\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        model.config.use_cache = False\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'].to('cuda'), attention_mask=batch['attention_mask'].to('cuda'), labels=batch['labels'].to('cuda'))\n",
    "        loss = outputs.loss\n",
    "        loss = loss / gradient_accumulation_steps  # Normalize loss\n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        global_step += 1\n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "        \n",
    "        if global_step % 20 == 0:\n",
    "            pred = generate_eval(model=model,idx=40,disable_lora=False)\n",
    "            print('*'*20,step+1,'*'*20)\n",
    "            print(\"Predictions:\", pred)\n",
    "            print('*'*20,'end','*'*20)\n",
    "            \n",
    "        if loss.item() < max_loss:\n",
    "            model.save_pretrained('/home/nas/buffer/mohan.dash/llama_3_finetuned/adapter')\n",
    "            max_loss = loss.item()\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f\"Epoch {global_step + 1}/{max_steps}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the LoRA and saving the Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_with_adapter.save_pretrained('/home/nas/buffer/mohan.dash/llama_3_finetuned/adapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the adapter into the base model\n",
    "model = PeftModel.from_pretrained(model, '/home/nas/buffer/mohan.dash/llama_3_finetuned/adapter')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଭୁବନେଶ୍ୱରର ରାଜାରାଣୀ ମନ୍ଦିରର ଇତିହାସ କ’ଣ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ପୂର୍ବ-ଗୋଟିଏ ଖୈଳଧଙ୍ଚ, ଯେଉଁଠି ଅଂଘାଡ଼ି ସୃଷ୍ଟି ଥିଲା। ଆଞ୍ଚଳିକ ସୌନ୍ଦର୍ଯ୍ୟ ସଫର କରିଛି, ଓ ସ୍ଥାନୀୟ ଔପନିବେଶକମାନେ ପ୍ରଵେଶ କରୁଛନ୍ତି।\n",
      "\" \" - ଢ. ପ୍ରୋଫେସର ଐ. ରେନି (1928) | ଏହା ତ୍ରୟୋଦଶ ଶତାବ୍ଦୀରେ ସମ୍ପର୍କିତ ଏକ ଜାରିବାର ପାଳନ କରୁଛି । ରାଜାରାଣୀ ଦୁ\n"
     ]
    }
   ],
   "source": [
    "pred = generate_eval(model,idx=40,disable_lora=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your saved checkpoint\n",
    "save_path = \"/home/nas/buffer/mohan.dash/llama_3_finetuned/model_checkpoint.pt\"\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(save_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Restore model, optimizer, scheduler, and step\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "global_step = checkpoint['global_step']\n",
    "\n",
    "# print(f\"Checkpoint loaded from {save_path} at step {global_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = checkpoint['global_step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/nas/buffer/mohan.dash/llama_3_finetuned/model_checkpoint.pt\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "    'global_step': global_step\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Checkpoint saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
